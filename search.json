[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m Patrick, and I’m a Machine Learning Engineer at Dedalus HealthCare where I’m building models for clinical risk prediction and NLP for health."
  },
  {
    "objectID": "blog/more-is-more/index.html",
    "href": "blog/more-is-more/index.html",
    "title": "More is More: An Analysis of Using Efficient Transformers for Fact-Checking",
    "section": "",
    "text": "For my Master’s thesis, I worked on the NLP task of fact-checking. It started out with the observation that current, traditional Transformers (such as BERT) can only handle a limited amount of evidence. That is because they have a quadratic memory complexity in the sequence length. Therefore, processing more evidence becomes quadratically more expensive with every token added.\nThe idea of my thesis is to analyse the effect of using more efficient Transformer models with sub-quadratic complexity to increase the amount of evidence they can process. Doing so increased prediction accuracy for long documents and reduced computational costs.\nIn this blog post, I will give an overview of my research. If you want to get a complete picture, have a look at my full thesis.\nWith this thesis, I have obtained my Master’s degree in computer science at Graz University of Technology. I worked on the project while employed at Buster.Ai, a Paris-based startup with a focus on NLP. I would like to thank the whole team once again for their support and the computational resources I was provided with."
  },
  {
    "objectID": "blog/more-is-more/index.html#what-is-fact-checking-why-should-i-care",
    "href": "blog/more-is-more/index.html#what-is-fact-checking-why-should-i-care",
    "title": "More is More: An Analysis of Using Efficient Transformers for Fact-Checking",
    "section": "What is fact-checking? Why should I care?",
    "text": "What is fact-checking? Why should I care?\nFalse information on and off the web is becoming increasingly common. Economic fallout, societal conflicts and health risks follow. Automatic fact-checking systems are one way to combat this ever more dangerous problem. In principle, they work like this: A claim that is to be verified is input into the system. It, then, predicts a verdict. This verdict is not (and cannot be) whether the claim is true or false since this would require the model to make definitive statements about the world. As this is infeasible, such systems resort to predicting whether a claim is supported or refuted by their evidence base (a.k.a. knowledge base). For example, for the famous fact-checking data sets FEVER and FEVEROUS, this evidence base is Wikipedia. Here is an example of such a claim from the FEVEROUS data set:\n\nThe evidence base (Wikipedia) is used to predict the verdict of the claim (Refuted)."
  },
  {
    "objectID": "blog/more-is-more/index.html#how-do-fact-checking-systems-work",
    "href": "blog/more-is-more/index.html#how-do-fact-checking-systems-work",
    "title": "More is More: An Analysis of Using Efficient Transformers for Fact-Checking",
    "section": "How do fact-checking systems work?",
    "text": "How do fact-checking systems work?\nFact-checking systems with explicit knowledge bases work as follows:\n\nA retrieval component extracts the relevant evidence (also called gold evidence) from the evidence base. In the previous example, this would be the Wikipedia article of Micheal McCafferty. Then, an entailment model predicts a verdict, i.e., whether the retrieved evidence supports or refutes the claim. The entailment task is also known as Natural Language Inference (NLI). Most state-of-the-art entailment models today are Transformers, which process one joint input sequence per sample. In the case of fact-checking, this means that the claim and the relevant evidence are concatenated into one long sequence of length \\(N\\).\n\nNaturally, the more evidence the model should process, the longer the input sequence becomes. However, as Transformers have quadratic complexity in the input length, adding more evidence becomes quadratically more expensive.\n\nTherefore, the sequence has to be cut off at some point.\n\n\n\n\n\n\nRoBERTa predictions on FEVER\nCutting off irrelevant evidence is obviously no problem, but cutting off gold evidence is. As you can see in this plot, samples for which the evidence has been cut off are significantly less likely to be correctly classified than samples for which the models have seen the gold evidence."
  },
  {
    "objectID": "blog/more-is-more/index.html#my-work",
    "href": "blog/more-is-more/index.html#my-work",
    "title": "More is More: An Analysis of Using Efficient Transformers for Fact-Checking",
    "section": "My Work",
    "text": "My Work\nThe idea of my thesis is relatively straight-forward:\nUse more efficient Transformers with sub-quadratic complexity that can handle more evidence.\nThe research questions I was aiming to answer were the following:\n\nDoes it improve prediction performance?\nDoes it reduce computational costs?\nWhich model works best?\nIs the approach still interpretable?\n\nFor doing so, I built a complete fact-checking pipeline with preprocessing, retrieval and entailment components. Let’s go through them.\n\nRetrieval\nWhile retrieval methods weren’t the focus of my work, the results of the retrieval step form the foundation of the pipeline. I, therefore, ran some experiments to find the ones who were best suited for my task.\nIn general, there are two broad categories of retrieval methods:\n\nSparse methods: These are based on classical information retrieval techniques and work with term frequency statistics. Famous examples are TF.IDF and BM25.\nDense methods: These approaches use dense neural networks (hence the name). A prominent example is Dense Passage Retrieval (DPR). The principle is relatively simple: All documents are projected into an embedding space, and the embeddings are stored in a database. At retrieval time, an embedding of the claim is computed, and the documents closest to it are returned. Common metrics for closeness are the dot-product and cosine similarity.\n\nIf you’re interested, the creators of the wonderful library haystack have written a more in-depth comparison.\nFor my purposes, I decided to focus on sparse retrieval with BM25 since it yielded sufficient results without further fine-tuning. It was a good baseline to compare entailment methods.\nHowever, this is not to say that I believe sparse methods are sufficient for all fact-checking applications. Their inability to handle synonyms is just the most glaring shortcoming of exact term matching. DPR isn’t the ideal solution either. For example, claims that require multi-hop reasoning (as nicely explained by Ostrowski, Wojciech et al.) require specialised methods, such as Multi-Hop Dense Retrieval (MDR). Due to cascading errors, the shortcomings of retrieval methods cannot entirely be mitigated by using more powerful entailment models. If the relevant evidence hasn’t at all been retrieved, the entailment model won’t be able to make up for that.\n\nNo Passage Retrieval\nMost fact-checking pipelines today use a two-step retrieval process:\n\nFirst, the relevant documents are retrieved and then the relevant passages therein. This second, so-called passage retrieval step is necessary to extract relevant passages from the documents and reduce the amount of information the entailment component needs to handle. However, as I’m using entailment models that can handle much larger input sequences, I can skip the passage retrieval component and simplify the retrieval step to this:\n\n\n\n\n\nThis removes the complexity and computational cost that the passage retrieval incurs. However, it also requires the entailment component to be better able to retrieve the relevant passages in the input sequence."
  },
  {
    "objectID": "blog/more-is-more/index.html#entailment",
    "href": "blog/more-is-more/index.html#entailment",
    "title": "More is More: An Analysis of Using Efficient Transformers for Fact-Checking",
    "section": "Entailment",
    "text": "Entailment\nThe core part of this work concerns the entailment component. The ones in my experiments can handle more evidence by replacing classical Transformer models with more efficient variants.\nAs a baseline, I use RoBERTa, which achieves quite good results for NLI at a moderate number of parameters. However, as it is a traditional quadratic Transformer, it can reasonably only handle up to 512 tokens in most current hardware settings.\nWhile there are a lot of Transformers with sub-quadratic complexity out there, I evaluated the following four, which cover a good mix of different techniques:\nLongformer: This model replaces the full self-attention component with a pattern approach whereby only local tokens, tokens within a dilated sliding window and global tokens can attend to each other. The Hugging Face Blog has a nice writeup if you’re interested in the details. For my experiments, I activated the global attention for all claim tokens. Thereby, the claim could attend to (and be attended to by) all evidence tokens.\nBig Bird: In principle, Big Bird is quite similar to Longformer. There are some important differences, such as random attention and a different global-local attention implementation, which lead to superior results in the original paper on multiple tasks. Hence, I also evaluated this model.\nFNet: In a very different fashion, FNet completely does away with the self-attention component and replaces it with a Fourier transform. The authors argue that this sufficiently mixes the tokens so that the feed-forward layers in the subsequent encoder blocks can learn across hidden and sequence dimension.\nPerceiver IO: This Deepmind model was built to support not only text but also other modalities such as images and audio. Its core idea is to project a large input into a much smaller latent space, on which attention blocks are applied. Therefore, the model’s complexity is no longer quadratic in the input length but in the latent size.\nThis was just a very brief overview of the methods. If you want to learn more, there are plenty of resources on the web. I also provide a more detailed description in my thesis.\n\nExtending Position Embeddings\nLongformer and Big Bird were specifically designed to handle longer input sequences. It is probably therefore that pre-trained checkpoints for 4096 tokens were available (allenai/longformer-base-4096, google/bigbird-roberta-base).\nHowever, for FNet and Perceiver IO, there are no weights available for configurations that can handle as much evidence as the other two. Since I lacked the computational resources to train them from scratch, I experimented with four ways of extending position embeddings: random initialisation, repetition, linear interpolation and nearest-neighbour interpolation.\n\n\n\nIllustration of extending position embeddings: Rows are the hidden dimension (\\(D=3\\)), and columns are the sequence dimension which is being extended from \\(N=3\\) to \\(N'=5\\).\n\n\nI found repetition to train fastest for FNet and nearest-neighbour interpolation for Perceiver IO. However, these are imperfect solutions, and it would likely have improved results to directly pre-train models for longer inputs with masked language modelling (MLM). From a personal learning perspective, it was still interesting to develop solutions to make this work in a resource-constrained setting."
  },
  {
    "objectID": "blog/more-is-more/index.html#evaluation",
    "href": "blog/more-is-more/index.html#evaluation",
    "title": "More is More: An Analysis of Using Efficient Transformers for Fact-Checking",
    "section": "Evaluation",
    "text": "Evaluation\nFinally, we get to the evaluation results. The data sets I used for comparing models and benchmarking overall performance were FEVER, FEVEROUS and FaVIQ. All three have Wikipedia as their evidence bases, but FEVER only contains the introductory paragraphs, while the others contain the full articles.\nTo better analyse how useful efficient Transformers are, I computed where in the input sequence the gold evidence was located for different data sets. After all, using a longer input sequence doesn’t make sense if the gold evidence is found in the beginning already.\n\nAll of these results are based on BM25 retrieval. For FEVER, a lot of gold evidence is before the cutoff line for RoBERTa (512 tokens), while for FEVEROUS, a lot more evidence is after that. To detach the entailment experiments from the retrieval method used, I also generated two synthetic retrieval inputs: In Gold far back, most gold evidence is after what RoBERTa can see, and in Uniform gold, it is uniformly distributed across the 4096 tokens.\nUnsurprisingly, in the gold far back setting, models that can look beyond token 512 have a big advantage and perform considerably better than RoBERTa:\n\nIn the uniform gold setting, which I used to compare all models, I found Longformer to perform best:\n\nIts performance increases when it sees more evidence and clearly beats the RoBERTa baseline. Big Bird develops similarly but consistently worse than Longformer. While Perceiver IO starts relatively promising, I found it to be hard to fine-tune to longer sequences. I suspect that this is because the encoder is hard to adjust to different position embeddings. FNet is outperformed by all other models, which is, however, not too surprising, given that it is also far behind RoBERTa on the GLUE NLI task.\nFinally, I evaluated the best-performing model, Longformer, on FEVER, FaVIQ and FEVEROUS and found that using longer sequences does improve performance:\n\nI also note, however, that on FEVEROUS, performance drops with longer sequence lengths, suggesting that the models are susceptible to noise, i.e., irrelevant evidence. My ablation study on this matter confirmed this hypothesis by showing that RoBERTa’s performance dropped from 95% accuracy when seeing only gold evidence to 86% when irrelevant evidence is appended."
  },
  {
    "objectID": "blog/more-is-more/index.html#key-findings",
    "href": "blog/more-is-more/index.html#key-findings",
    "title": "More is More: An Analysis of Using Efficient Transformers for Fact-Checking",
    "section": "Key Findings",
    "text": "Key Findings\nOverall, I find that feeding more evidence does improve entailment label accuracy. Hence, the title of this thesis is More is More. As for the answers to the research questions (simplified and condensed):\n\nDoes using more efficient Transformers that can handle more evidence improve prediction performance?\n\nYes, for longer input documents.\nYes, if the evidence is only retrieved relatively far back.\nOnly slightly in real-world retrieval results.\n\nDoes it reduce computational costs?\n\nOnly slightly when just swapping out the entailment component, i.e., replacing RoBERTa with Longformer.\nYes, significantly by completely skipping the passage retrieval step, which typically makes up around 35-45% of the inference time.\n\nWhich model works best?\n\nOut of the ones I experimented with, Longformer.\n\nIs the approach still interpretable?\n\nNot out of the box. Due to the removal of the passage retrieval step, this pipeline cannot exhibit which passages it considered for its decision. It can only provide this information on a document level."
  },
  {
    "objectID": "blog/more-is-more/index.html#conclusion",
    "href": "blog/more-is-more/index.html#conclusion",
    "title": "More is More: An Analysis of Using Efficient Transformers for Fact-Checking",
    "section": "Conclusion",
    "text": "Conclusion\nUsing efficient Transformers allowed me to reach 97-99% of the state-of-the-art performance on the FEVER data set at only 40-60% of the inference time. This is made possible by efficient BM25 document retrieval, but primarily because using efficient Transformers allows for completely skipping the passage retrieval step.\nWhile these models obtain impressive results on the data sets they were trained on, plenty of challenges still lie ahead of us. To name a few: Models should become better at handling irrelevant evidence; they should know what they don’t know and be able to explain how they came up with their verdicts.\nIn any case, I enjoyed working on this challenging task and am eager to see how the field develops in the future. I believe that the use of more efficient Transformer models has the potential for unlocking new levels of fact-checking performance with respect to both predictive and computational performance."
  },
  {
    "objectID": "blog/ndpretty/index.html",
    "href": "blog/ndpretty/index.html",
    "title": "ndpretty",
    "section": "",
    "text": "I created a little Python module to display numpy ndarrays in a pretty table in Jupyter notebooks. Find the code on GitHub or get it with pip install ndpretty.\n\nRecently I got into using Jupyter notebooks a lot. After watching Jeremy Howard’s great talk I like notebooks, I finally decided to make the jump and replace my beloved PyCharm by Jupyter notebooks as my primary development environment. As I’m not too big of a fan of doing everything in the browser, I went to Visual Studio Code with its truly excellent notebook support. I know that there is also notebook support in PyCharm, but it just always felt buggy and unpleasant to use.\nEverything went well, but there was one big thing that annoyed me and that I missed from PyCharm: Looking at numpy arrays. I’m quite a visual person and enjoy looking at what my matrices and tensors look like. This is why I loved the PyCharm SciView so much:\n\n\n\nPyCharm’s SciView for numpy arrays\n\n\nWhen looking at them in VS code’s notebook environment, they rather looked like this, and I wasn’t a big fan:\n\nWhile it’s quite okay for small arrays, I missed grasping the data by the colour highlighting and simply scrolling through a table. Also, I found I didn’t seem to be the only one with this problem, as these issues suggest. I then also explored some alternatives but wasn’t quite happy with the results either.\nTherefore I just built my own thing. It’s called ndpretty, as it displays ndarrays in a pretty way.\nIt makes use of the flexibility offered by Jupyter notebooks. In fact, it just prints a coloured HTML table – there’s not much magic there. In order to make it that bit more convenient, I also used ipywidgets to give users the possibility to slice the arrays in a text field right above the table:\n\nThat’s quite convenient if you also want to look at arrays with dimension higher than two. Also, for very big arrays, I perform automatic slicing so that your Jupyter notebook doesn’t get sluggish due to huge HTML tables:\n\nTo make it the default way of displaying numpy arrays, I register them as IPython third-party formatters.\nOverall, I’m quite happy with it, and I plan on using it a lot for my upcoming projects. You can look at the code at GitHub and get it with pip install ndpretty. Usage is as easy as importing it and calling ndpretty.default(). All subsequently executed cells that return a numpy array (or a PyTorch tensor) will be displayed using ndpretty. More customisation options are explained in the documentation.\nIf you want to try it out right now:"
  },
  {
    "objectID": "blog/stock-tweets/index.html",
    "href": "blog/stock-tweets/index.html",
    "title": "Stock Tweets",
    "section": "",
    "text": "I recently finished my Bachelor’s degree in business administration at the University of Graz. For my thesis, I combined machine learning with finance. The project is called Sentiment for Price Prediction (SePP), and I’m predicting stock price movements based on investors’ opinions, or at least what they are saying on Twitter about it. The purpose was to examine their tweets’ effect on the stock price – not to get rich or “beat the market”.\nHere’s the abstract:\n\nStock prices are inﬂuenced by investors’ beliefs, which many express on social media. As recent advances in machine learning have achieved impressive results in detecting sentiment in human language, this thesis aims to apply them to the task of stock price prediction. We present a machine learning model that takes as input tweets about certain assets, derives their sentiments and predicts whether the stock price will go up or down after that. Our model achieves a new state of the art in prediction accuracy on the StockNet data set and demonstrates that tweet sentiments have a discernible effect on stock prices.\n\nIf you’re interested, take a look at the full thesis or the code.\n\n\n\nFigure 1: Model architecture\n\n\nFigure 1 shows one architecture I experimented with: Inputs are tweets about a certain stock on a certain day. The first component detects the sentiments of tweets, for example, if a user expresses positive or negative feelings towards the stock. I used models such as BERT, RoBERTa and ALBERT for that. The sentiments are then weighed by the number of followers the tweet’s author has. Finally, a prediction is made about whether the stock price is likely to go up or down as a reaction."
  },
  {
    "objectID": "blog/author-attribution/index.html",
    "href": "blog/author-attribution/index.html",
    "title": "Author Attribution: DerStandard forum writing style",
    "section": "",
    "text": "This is a fun project my friend Lukas and I worked on for a course on natural language processing (NLP). We used the One Million Posts Corpus which contains user comments posted to the Austrian newspaper DerStandard. The goal was to perform author attribution, so to determine the author of a forum post.\nTo do so, we mainly looked at the writing style of the post, as this was mainly an exercise in the field of NLP. We call the attributes that give away a user based on their writing style stylometric. There has been a lot of research in this field and for our analysis, we mainly looked at rather classical features such as alpha-char-ratio, punctuation, lengths, etc.\nHowever, to make it more interesting, we also looked at how these features compared to taking into account other metadata and the actual post’s content for the predictions. In the end we looked at the following:\nOur model was a deep neural network with recurrent layers (primarily GRUs) for the content embeddings and a separate dense structure for the other input features:\nObviously we did some model selection to find the ideal number of layers and the configuration of hyper-parameters."
  },
  {
    "objectID": "blog/author-attribution/index.html#key-findings",
    "href": "blog/author-attribution/index.html#key-findings",
    "title": "Author Attribution: DerStandard forum writing style",
    "section": "Key findings",
    "text": "Key findings\nThe main things we found were the following:\n\nWe were best able to predict the post authors when using the stylometric features and the named entities of the articles itself. The latter allows for the assumption that people tend to comment on articles in the same genre.\nThe statistics on post dates weren’t as helpful as we had thought. Users don’t seem to have a clear enough posting routine to make accurate predictions based on the day or time they are posting.\nEven the very simple stylometric features we used already yielded quite good prediction results. In future work, it might make sense to look at this in detail and try to find out how to squeeze most out of the writing style alone.\n\nOverall, it was a very fun project with much room for further analysis. In case you want to check out all of what we did, you can find the full report on GitHub."
  },
  {
    "objectID": "blog/security-in-container-orchestration/index.html",
    "href": "blog/security-in-container-orchestration/index.html",
    "title": "Security in Container Orchestration",
    "section": "",
    "text": "I wrote my bachelor’s thesis on the issue of security in container orchestration, specifically in Kubernetes:\n\nContainerisation is increasingly gaining traction to run modern applications in distributed environments. To run containers on a large scale and with high availability, container orchestration systems are commonly employed. The most widely used container orchestration system today is Kubernetes, which is highly ﬂexible, but also comes with signiﬁcant complexity.\n\n\nIn this thesis, we analyse the security of Kubernetes architectures. To do so, we create a layer model to give a holistic view of all relevant aspects. We demonstrate how an example application can securely run in a Kubernetes cluster and which conﬁgurations are necessary to strengthen security by employing multiple redundant barriers.\n\n\nOur research shows that most Kubernetes installers already come with reasonably secure default conﬁgurations. However, custom adaptations in consideration of the deployed applications and their requirements to the runtime environment are imperative for secure cluster setup.\n\nIn short, I tried to get a holistic view of the relevant security aspects of container orchestration in Kubernetes and categorised them into a layer model.\n\n\n\nMy layer architecture for categorising Kubernetes security aspects\n\n\nI demonstrated my model with a sample architecture run on Google Kubernetes Engine. At the time of this writing, most Kubernetes installers already come with relatively secure default setups. However, there are still plenty of pitfalls and things to look out for in order not to end up in a bad place.\nIf you’re interested, you can read my full thesis here."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello! This is work in progress.",
    "section": "",
    "text": "More is More: An Analysis of Using Efficient Transformers for Fact-Checking\n\n\n\n\n\n\n\nnlp\n\n\nml\n\n\nresearch\n\n\n\n\n\n\n\n\n\n\n\nJun 13, 2022\n\n\nPatrick Deutschmann\n\n\n\n\n\n\n  \n\n\n\n\nModelling Air Pollution Transfers for Prediction, Analysis and Simulation\n\n\n\n\n\n\n\nml\n\n\n\n\n\n\n\n\n\n\n\nJan 30, 2022\n\n\nPatrick Deutschmann\n\n\n\n\n\n\n  \n\n\n\n\nStock Tweets\n\n\n\n\n\n\n\nml\n\n\nfinance\n\n\n\n\n\n\n\n\n\n\n\nNov 18, 2021\n\n\nPatrick Deutschmann\n\n\n\n\n\n\n  \n\n\n\n\nDependable Classification\n\n\n\n\n\n\n\nml\n\n\n\n\n\n\n\n\n\n\n\nJul 24, 2021\n\n\nPatrick Deutschmann\n\n\n\n\n\n\n  \n\n\n\n\nndpretty\n\n\n\n\n\n\n\npython\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2021\n\n\nPatrick Deutschmann\n\n\n\n\n\n\n  \n\n\n\n\nWhose Food?\n\n\n\n\n\n\n\nml\n\n\n\n\n\n\n\n\n\n\n\nDec 12, 2020\n\n\nPatrick Deutschmann\n\n\n\n\n\n\n  \n\n\n\n\nAuthor Attribution: DerStandard forum writing style\n\n\n\n\n\n\n\nnlp\n\n\nml\n\n\n\n\n\n\n\n\n\n\n\nJul 12, 2020\n\n\nPatrick Deutschmann\n\n\n\n\n\n\n  \n\n\n\n\nNeural Collaborative Filtering in SystemDS\n\n\n\n\n\n\n\nml\n\n\n\n\n\n\n\n\n\n\n\nJul 5, 2020\n\n\nPatrick Deutschmann\n\n\n\n\n\n\n  \n\n\n\n\nSecurity in Container Orchestration\n\n\n\n\n\n\n\nresearch\n\n\nops\n\n\nsecurity\n\n\n\n\n\n\n\n\n\n\n\nAug 30, 2019\n\n\nPatrick Deutschmann\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/dependable-classification/index.html",
    "href": "blog/dependable-classification/index.html",
    "title": "Dependable Classification",
    "section": "",
    "text": "My friend Lukas and I participated in the Siemens Mobility AI Dependability Assessment, built a deep neural network classifier with safety guarantees and won a prize.\nThe basis of the task was a simple binary 2D classification problem, i.e., given inputs samples with two features, we need to assign them either class 0 or 1. The interesting part was that we were operating in a safety-critical setting. Therefore, our predictions should be reliable in that we should give guarantees for our misclassification rate. Also, making errors isn’t symmetrically bad. Take the example of a traffic light: If our algorithm were in charge of deciding whether to stop or go, it would be much worse if we ran over a red light than unnecessarily stopping at a green light. Hence, incorrectly classifying a green sample as red is much more costly than classifying a red one as green."
  },
  {
    "objectID": "blog/dependable-classification/index.html#our-solution",
    "href": "blog/dependable-classification/index.html#our-solution",
    "title": "Dependable Classification",
    "section": "Our solution",
    "text": "Our solution\nAfter comparing different approaches, we settled on using a deep neural network. Yes, we brought in the big guns. Even though the data sets weren’t too complex, the goal was to design an approach that scaled to higher dimensions and, possibly, also translated to different problem domains such as vision tasks. We compared performance to some baseline approaches such as SVM – which would have allowed for much simpler safety bound computations – but didn’t achieve satisfying results. Hence, we went with a multi-layer deep neural network.\nHowever, typically, deep neural networks are textbook examples of black-box models. To give safety guarantees, we used local perturbation analysis. Thereby we could ensure that inputs that lie within a certain epsilon environment of previously seen samples will be classified as seen in the training.\nIn the following illustration, the guaranteed epsilon environments appear as circles or squares, depending on whether an \\(L_2\\) or \\(L_\\infty\\) norm defines the epsilon environment best. In simple terms: All inputs within green circles will be classified as green, whereas all inputs within red circles will be classified as red:\n\n\n\n\n\n\n\n\\(L_2\\)\n\n\n\n\n\n\n\n\\(L_\\infty\\)\n\n\n\n\nFigure 1: Epsilon environments\n\n\nFor deep neural networks, it is non-trivial to come up with these guarantees. In fact, finding an exact solution is NP-complete. For our submission, we rely on an approximation approach that has been introduced at NeurIPS 2020. It is called auto_LiRPA, and it’s a framework for automatically deriving bounds using linear relaxations. Using these bounds, we can derive the epsilon environments, define safety-related accuracy metrics and provide the required guarantees.\nThere were plenty more little challenges in this project, and we wrote a detailed report about it.\nThe code is on GitHub. All in all, this was a fun and challenging project where we learned a lot and were also awarded a runner’s up prize.\nThanks, Siemens, and thanks, Lukas, for taking this on with me!"
  },
  {
    "objectID": "blog/modelling-air-pollution/index.html",
    "href": "blog/modelling-air-pollution/index.html",
    "title": "Modelling Air Pollution Transfers for Prediction, Analysis and Simulation",
    "section": "",
    "text": "Illustration of PM2.5 transfers from Wang et al. (2020)\n\n\nLast spring, I worked on an exciting project in the course of my master’s studies. I designed a graph-based neural network that predicts air pollution and builds on the basic observation that the concentration of pollutants is often affected by transfer events. Unfortunately, I’m just getting to blog about it now, but I felt like it was too interesting not to publish it. I was supervised by Olga Saukh from TU Graz and Yun Cheng from ETH Zürich.\nAir pollution appears in various shapes and forms and is affected by a multitude of factors. In one of the simplest cases, the wind carries pollutants from where they were emitted to different locations. Our approach uses current concentration levels, geographical properties, wind and weather features to predict future pollution.\n\n\n\nModel predictions over time\n\n\nIn order to do so, we extend existing work by replacing a core component with an interpretable pollution transfer matrix. This can then be used to analyse the influence of specific locations on different ones: Thereby, the predictions are interpretable, and the model can provide information about where it predicts transfers to take place.\n\n\n\nInfluence of surrounding cities on Qianmen\n\n\n\n\n\nTransfer matrix\n\n\nOur method achieves performances comparable to the state-of-the-art for short-term predictions while also explaining its results. Moreover, it can simulate how reducing emissions at one location would impact air pollution in the area.\nIf you’re interested in the details, you can check out my report."
  },
  {
    "objectID": "blog/neural-collaborative-filtering-in-systemds/index.html",
    "href": "blog/neural-collaborative-filtering-in-systemds/index.html",
    "title": "Neural Collaborative Filtering in SystemDS",
    "section": "",
    "text": "Neural Collaborative Filtering (NCF) is a fairly new approach to recommender systems proposed by He et al. It is aimed at tackling the problem of collaborative filtering, such as the Netflix problem which is about predicting users’ ratings for films they haven’t yet seen based on what they have seen before.\nWhile most work in this field in the past has employed classical matrix factorisation approaches, the idea of NCF is to replace this by one or more neural layers:\nIn a nutshell, NCF removes the restriction that the only interaction function between users and items can be an inner product in the latent feature space. It hence allows for modelling more complicated decision behaviour.\nI found this idea intriguing and implemented it in SystemDS, a machine learning system designed for large scale operations and automatic optimisation. Why? Because I could. And because it was part of a project for the course Architectures of Machine Learning Systems in my computer science master programme."
  },
  {
    "objectID": "blog/neural-collaborative-filtering-in-systemds/index.html#data-set",
    "href": "blog/neural-collaborative-filtering-in-systemds/index.html#data-set",
    "title": "Neural Collaborative Filtering in SystemDS",
    "section": "Data set",
    "text": "Data set\nI try this all out with the infamous MovieLens data set:\n\nThis dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018.\n\n\nUsers were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n\nAs in the original NCF paper, the targets are binary and only indicate whether a user has rated a movie or not. This makes the recommendation problem harder than working with the values of the ratings. It is, however, closer to a real-world use case, as interaction data is easier to collect in practice.\nMovieLens only provides positive interactions in form of ratings. I therefore randomly sample negative interactions as suggested by the original paper. They simply represent movies the user hasn’t yet interacted with."
  },
  {
    "objectID": "blog/neural-collaborative-filtering-in-systemds/index.html#conclusion",
    "href": "blog/neural-collaborative-filtering-in-systemds/index.html#conclusion",
    "title": "Neural Collaborative Filtering in SystemDS",
    "section": "Conclusion",
    "text": "Conclusion\nThe bottom line is that it worked quite well in my experimental setting:\n\nAs in the original paper, it outperformed some traditional matrix factorisation approaches I tried.\nHowever, the point of this project wasn’t really to optimise prediction results by optimising the hyper-parameters, but rather to implement the architecture in SystemDS to test its real-world feasibility as a machine learning system. The implementation can later be used to benchmark the system where it can show off the optimisations it does.\nWhat’s left to say? My pull request has recently been merged. 🎊 And I’ve learnt quite something about how it feels to work with a lower-level system with fewer abstractions than, for example, Keras or PyTorch."
  },
  {
    "objectID": "blog/whose-food/index.html",
    "href": "blog/whose-food/index.html",
    "title": "Whose Food?",
    "section": "",
    "text": "I used transfer learning to predict what my friends are eating. The code is on GitHub.\nThe long version of the story goes like this: Some of my friends and I have this silly WhatsApp group where we share photos of what we eat – all of what we eat. From breakfast, over lunch until dinner, including all tiny snacks during the day. It’s more of a fun thing, not a serious endeavour, but it made me a bit more conscious about what I eat.\nSince we have been doing this for almost a year now, we have built up a fairly reasonable record of our eating patterns. We also started to develop a sense for the habits of the others. Without looking at who sent the photo, we can now almost immediately identify whose food this probably was.\nSo I started wondering whether this was enough data to predict who was eating what using a machine learning model. Our chat contains 8137 messages, of which 4201 are photos.\nI decided to give it a shot. The task is a simple classification problem: Given a photo, find the friend who posted it. I exported the files from WhatsApp, extracted the labels and some date information using pandas and made some quality checks."
  },
  {
    "objectID": "blog/whose-food/index.html#architecture",
    "href": "blog/whose-food/index.html#architecture",
    "title": "Whose Food?",
    "section": "Architecture",
    "text": "Architecture\nUnfortunately, I didn’t have enough data to train a model from scratch, so I went ahead and used transfer learning. I fired up PyTorch and grabbed myself a ResNet (from Deep Residual Learning for Image Recognition) that’s pre-trained on ImageNet. Then I attached a linear layer for my classification targets to the final fully connected layer of the ResNet.\nI was then faced with the decision of how to train my model: Should I fine-tune the ResNet’s weights or should I freeze them and only train my linear classifier on top of the ResNet codes? I had a small dataset that is, however, also quite different from ImageNet, and I feared that freezing the ResNet’s weights might underfit my data. Some resources confirmed my expectation. Obviously, it would be much quicker to train, though. So I decided to test both approaches and then compare the results.\nAs an optimisation criterion, I used cross-entropy loss, as I posed my problem as a classification task with multiple target classes. In reality, however, the problem is a multi-label classification task, as every food could have been consumed by multiple people. Having said that, I didn’t have the data to set up my model accordingly and, hence, decided to go forward with cross-entropy.\nBefore starting my training, I did some expectation management:\n\nIf the network just outright guessed whose food it could be, it would get one in five correct, leading to a conservative baseline accuracy of 0.2.\nI did some (admittedly, very unscientific) human testing and tried out how many foods I could correctly classify. I got around 8-9 out of 10 correct. So if my model were to meet human performance, it would reach an accuracy between 0.8 and 0.9."
  },
  {
    "objectID": "blog/whose-food/index.html#results",
    "href": "blog/whose-food/index.html#results",
    "title": "Whose Food?",
    "section": "Results",
    "text": "Results\nNow I let my poor laptop train a few networks. I always trained for 25 epochs and didn’t make any use of early stopping or other mechanisms that would likely have helped to squeeze a few more per cent out of the network.\nHere are the results I obtained:\n\nEven with ResNet-18, I got very high predictive results – far better than I had expected. It seems that my model easily attains the human goal I had described before. As I had expected, the models with frozen weights that just trained the linear classifier performed much worse than when I was also training the ResNet’s weights.\nFirst, I was a bit surprised to see that in all models, the test accuracy was better than the training accuracy. I’m neither using Dropout nor am I performing any crops or rotations only on the training set that I’m not doing on the test set. I also had done my homework in checking for reasonable loss values at the beginning of the training and overfitting a tiny subset of the data. Finally, I found the source of the behaviour to probably lie in the use of batch normalisation in the ResNet.\nHere is a confusion matrix showing the true predictions next to the false positives and negatives:\n\n\n\nConfusion matrix"
  },
  {
    "objectID": "blog/whose-food/index.html#insights",
    "href": "blog/whose-food/index.html#insights",
    "title": "Whose Food?",
    "section": "Insights",
    "text": "Insights\nI almost couldn’t believe the good results and suspected overfitting. Even if the metrics on the test set are quite promising, my data set is tiny, and I imagined that my models didn’t truly understand what my friends are eating. Maybe they just focused a lot on what the surroundings looked like.\nFor instance, if you look at the images about which the network is most sure that they are mine, you can see that they mostly contain my plate in the background:\n\n\n\nClassic Patrick food (please don’t judge my diet)\n\n\nTo confirm my hypothesis, I looked at the activations of the ResNet by adding a hook to the forward passing using the very convenient register_forward_hook. I obtained the clearest results by looking at the first layer of the ResNet.\nWas my hypothesis confirmed? See for yourself:\n\n\n\nLeft: input image, Right: activation of the first layer of the ResNet\n\n\nNope. It was the Babybel that gave me away. (Yes, I know, but it’s a guilty pleasure.) I also looked at quite a few of the other images and didn’t find any evidence that the network would focus on picture areas that don’t contain food but surroundings."
  },
  {
    "objectID": "blog/whose-food/index.html#conclusion",
    "href": "blog/whose-food/index.html#conclusion",
    "title": "Whose Food?",
    "section": "Conclusion",
    "text": "Conclusion\nAs you will surely have realised by now, this project was not too scientific, and my data set was way too small. Here’s actually a list of all the things I could have done to go further in this project:\n\nexplore simpler classifications methods to establish better baselines\ncreate a better top-performance estimation than my somewhat naïve approach\nlook at different metrics and losses\ntry other network architectures and train them longer\nperform more in-depth hyper-parameter searches\nuse more and different data augmentation techniques to enlarge my data set\nlook deeper into the networks’ activations\nbaby-sit the training process more (adjusting optimisers, looking at learning rates, etc.)\netc.\n\nBut, I still solved a real-world “problem” using transfer learning, obtained quite good results and had some fun pictures to show to my friends. Also, I learned a lot. Mainly that when employing advanced methods, you shouldn’t move too fast. I felt like taking baby steps and sanity-checking the intermediate results is a far better approach than back-tracking after you find yourself in a super weird situation."
  }
]